import joblib
import pandas as pd
from tensorflow.keras.models import load_model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import RobustScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_validate
from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score
from sklearn.ensemble import GradientBoostingClassifier
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)
pd.set_option('display.width', 1000)
pd.set_option('display.precision', 2)
pd.set_option('display.float_format', '{:.2f}'.format)
path = "/kaggle/input/playground-series-s4e1/test.csv"
train = pd.read_csv("/content/train.csv")
test = pd.read_csv("/content/test.csv")
sub = pd.read_csv("/content/sample_submission.csv")
train.drop(columns=["CustomerId", "Surname"], axis=1, inplace=True)

def model_dl(dataframe, target, targetsize, randomstate):
    loaded_data = joblib.load('preprocess_bank.pkl')
    
    # X and y separation
    X = dataframe.drop(target, axis=1)
    y = dataframe[target]

    # Separate categorical and numerical columns
    categorical_c = X.select_dtypes(include="object").columns
    numerical_c = X.select_dtypes(include=["float64", "int64"]).columns

    print(f"Categorical Col: {categorical_c}")
    print(f"Numerical Col: {numerical_c}")

    # Pipelines for categorical and numerical data
    categorical_pipi = Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OneHotEncoder(handle_unknown='ignore'))
    ])
    numerical_pipi = Pipeline([
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', RobustScaler())
    ])

    # Column transformer to process the data
    process = ColumnTransformer([
        ('cat', categorical_pipi, categorical_c),
        ('num', numerical_pipi, numerical_c)
    ])

    # Split the data into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=targetsize, random_state=randomstate)


    X_train_tn=process.fit_transform(X_train)
    X_test_tn=process.transform(X_test)

    joblib.dump(process, 'preprocess_pipeline_keras.pkl')
    model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_tn.shape[1],)),
    Dense(32, activation='relu'),
    Dense(16, activation='relu'),
    Dense(1,  activation="sigmoid")])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

    # Model checkpoint callback
    checkpoint = ModelCheckpoint(
        'best_model.h5.keras',  
        monitor='val_loss',  
        save_best_only=True,  
        mode='min',  
        verbose=1)
    history=model.fit(X_train_tn, y_train, epochs=100, batch_size=32, validation_data=(X_test_tn, y_test), callbacks=[early_stopping, checkpoint],validation_split=0.25)

    best_model = load_model('best_model.h5.keras')
    
    # Make predictions
    y_pred_proba = best_model.predict(X_test_tn)
    
    # Calculate AUC
    auc_score = roc_auc_score(y_test, y_pred_proba)
    print(f"AUC Score: {auc_score:.4f}")

    # Save the final model
    joblib.dump(best_model, 'final_model.pkl')

 
model_dl(train, "Exited", 0.25, 4) #### AUC Score: 0.8886
